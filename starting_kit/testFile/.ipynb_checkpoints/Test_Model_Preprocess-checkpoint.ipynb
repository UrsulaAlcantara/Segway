{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dir = './ingestion_program/'  \n",
    "score_dir = './scoring_program/'\n",
    "model_dir = './sample_code_submission/'\n",
    "result_dir = './sample_result_submission/'\n",
    "path.append(model_dir); path.append(problem_dir); path.append(score_dir);\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_io'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d09bc0a6ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_as_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./all_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'xporters'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_as_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_io'"
     ]
    }
   ],
   "source": [
    "from data_io import read_as_df\n",
    "data_dir = './all_data'\n",
    "data_name = 'xporters'\n",
    "data = read_as_df(data_dir  + '/' + data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing + Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Imports\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_name = [\n",
    "    'Raw data',\n",
    "    'Remove Outliers',\n",
    "    'PCA',\n",
    "    'SVD',\n",
    "    'TSNE',\n",
    "    'VarianceThreshold',\n",
    "    'SelectKBest',\n",
    "    'SelectFromModel'\n",
    "]\n",
    "\n",
    "# Shuffle data\n",
    "shuffle = data.copy()\n",
    "shuffle = shuffle.reindex(np.random.permutation(shuffle.index))\n",
    "shuffle = shuffle.head(3000)\n",
    "Y_raw = shuffle.iloc[:,-1]\n",
    "print(\"Shuffle Complete\")\n",
    "\n",
    "# Remove Outliers\n",
    "outliers = shuffle.copy()\n",
    "outliers['outliers'] = pd.Series(LocalOutlierFactor(n_neighbors= 200).fit_predict(outliers), \n",
    "                                 index = outliers.index)\n",
    "outliers = outliers[outliers['outliers'] == 1]\n",
    "outliers = outliers.drop('outliers', 1)\n",
    "Y = outliers.iloc[:,-1]\n",
    "X = outliers.iloc[:,0:-1]\n",
    "print(\"Remove Outlier Complete\")\n",
    "\n",
    "# Scaler\n",
    "scaled_data = pd.DataFrame(StandardScaler().fit_transform(outliers))\n",
    "Y_scaled = scaled_data.iloc[:,-1]\n",
    "X_scaled = scaled_data.iloc[:,0:-1]\n",
    "print(\"Scaler Complete\")\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components = 4).fit_transform(scaled_data)\n",
    "print(\"PCA Complete\")\n",
    "\n",
    "# SVD\n",
    "svd = TruncatedSVD(n_components=4).fit_transform(scaled_data)\n",
    "print(\"SVD Complete\")\n",
    "\n",
    "# TSNE\n",
    "tsne = TSNE().fit_transform(scaled_data)\n",
    "print(\"TSNE Complete\")\n",
    "\n",
    "# Feature Selection\n",
    "# VarianceThreshold\n",
    "p = 0.9 \n",
    "vart = VarianceThreshold(threshold=p*(1-p))\n",
    "vart = vart.fit_transform(X)\n",
    "print(\"VarianceThreshold Complete\")\n",
    "\n",
    "# SelectKBest\n",
    "slck = SelectKBest(chi2, k=15)\n",
    "slck = slck.fit_transform(X, Y)\n",
    "print(\"SelectKBest Complete\")\n",
    "\n",
    "# SelectFromModel LassoCV\n",
    "slcm = SelectFromModel(LassoCV(), max_features=10).fit(X_scaled, Y_scaled)\n",
    "slcm = slcm.transform(X_scaled)\n",
    "print(\"SelectFromModel LassoCV Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize = (11, 11))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(svd[:, 0], svd[:, 1], svd[:, 2], c = svd[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot()\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (11, 11))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca[:, 0], pca[:, 1], pca[:, 2], c = pca[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to Panda Dataframe\n",
    "pca = pd.DataFrame(pca)\n",
    "svd = pd.DataFrame(svd)\n",
    "tsne = pd.DataFrame(tsne)\n",
    "vart = pd.DataFrame(vart)\n",
    "slck = pd.DataFrame(slck)\n",
    "slcm = pd.DataFrame(slcm)\n",
    "print(\"Transform to Panda Dataframe Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring fonction\n",
    "score_dir = 'scoring_program/'\n",
    "path.append(score_dir)\n",
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model List\n",
    "voter1 = GradientBoostingRegressor()\n",
    "voter2 = RandomForestRegressor()\n",
    "voter3 = DecisionTreeRegressor()\n",
    "\n",
    "model_name = [\n",
    "    'KNeighbors',\n",
    "    'SVR',\n",
    "    'GaussianProcess',\n",
    "    'ElasticNet',\n",
    "    'DecisionTree',\n",
    "    'RandomForest',\n",
    "    'GradientBoosting',\n",
    "    'Voting - GB - DT',\n",
    "    'Voting - GB - DT - RF']\n",
    "\n",
    "model_list = [\n",
    "    KNeighborsRegressor(n_neighbors=5),\n",
    "    svm.SVR(),\n",
    "    GaussianProcessRegressor(), \n",
    "    ElasticNet(),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(max_depth=9),\n",
    "    GradientBoostingRegressor(),\n",
    "    VotingRegressor(estimators=[('gb', voter1), ('lr', voter3)]),\n",
    "    VotingRegressor(estimators=[('gb', voter1), ('rf', voter2), ('lr', voter3)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_data(data_test,Y,data_name) :\n",
    "    res = {}\n",
    "    perf = []\n",
    "    X = data_test\n",
    "    for i in range(len(model_list)) :\n",
    "        model = model_list[i]\n",
    "        s = cross_val_score(model, X, Y, cv=5, scoring=make_scorer(scoring_function))\n",
    "        s = s.mean(), s.std() * 2\n",
    "        print('CV score for the', model_name[i], '= %0.2f (+/- %0.2f)' %s)\n",
    "        res[data_name+' - '+model_name[i]] = s[0]\n",
    "        if s[0]<0:\n",
    "            perf.append(0)\n",
    "        else:\n",
    "            perf.append(round(s[0],3))\n",
    "    print('\\n')\n",
    "    return res,perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "perf = np.ones((8,9))\n",
    "\n",
    "print('score - data original: ')\n",
    "shuffle = shuffle.iloc[:,:-1]\n",
    "r,p = score_data(shuffle, Y_raw, 'data original')\n",
    "res.update(r)\n",
    "perf[0] = np.array(p)\n",
    "\n",
    "print('score - data no outliers: ')\n",
    "outliers = outliers.iloc[:,:-1]\n",
    "r,p = score_data(outliers, Y, 'data no outliers')\n",
    "res.update(r)\n",
    "perf[1] = np.array(p)\n",
    "\n",
    "print('score - data of PCA: ')\n",
    "r,p = score_data(pca, Y, 'data of PCA')\n",
    "res.update(r)\n",
    "perf[2] = np.array(p)\n",
    "\n",
    "print('score - data of SVD: ')\n",
    "r,p = score_data(svd, Y, 'data of SVD')\n",
    "res.update(r)\n",
    "perf[3] = np.array(p)\n",
    "\n",
    "print('score - data of TSNE: ')\n",
    "r,p = score_data(tsne, Y_scaled, 'data of TSNE')\n",
    "res.update(r)\n",
    "perf[4] = np.array(p)\n",
    "\n",
    "print('score - data of VarianceThreshold: ')\n",
    "r,p = score_data(vart, Y, 'data of TSNE')\n",
    "res.update(r)\n",
    "perf[5] = np.array(p)\n",
    "\n",
    "print('score - data of SelectKBest: ')\n",
    "r,p = score_data(slck, Y, 'data of TSNE')\n",
    "res.update(r)\n",
    "perf[6] = np.array(p)\n",
    "\n",
    "print('score - data of SelectFromModel LassoCV: ')\n",
    "r,p = score_data(slcm, Y_scaled, 'data of TSNE')\n",
    "res.update(r)\n",
    "perf[7] = np.array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Combination: \" + max(res,key=res.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = np.array(perf)\n",
    "com_perf = pd.DataFrame(perf, columns=model_name, index=preprocessing_name)\n",
    "com_perf.round(3).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.py Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(data_name, data_dir, replace_missing=True)\n",
    "\n",
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(X_train)\n",
    "d[-1] = Y_train\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import model\n",
    "\n",
    "M = model()\n",
    "trained_model_name = model_dir + data_name\n",
    "\n",
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']\n",
    "if not(M.is_trained) : M.fit(X_train, Y_train)                 \n",
    "Y_hat_train = M.predict(D.data['X_train']) # Optional, not really needed to test on taining examples\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check\n",
    "np.vstack((Y_hat_train,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Result\n",
    "from data_io import write\n",
    "result_name = result_dir + data_name\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.scatter(Y_train, Y_hat_train, alpha ='0.5', s = 1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Valid\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(M, X_train, Y_train, cv=5, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = './sample_code_submission_' + the_date + '.zip'\n",
    "sample_result_submission = './sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
